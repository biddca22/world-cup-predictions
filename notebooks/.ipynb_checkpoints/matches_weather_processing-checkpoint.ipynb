{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "839be815-22dd-473f-aa33-cd56fbfee5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Load clean match dataset\n",
    "df = pd.read_csv('../data-processed/matches_clean.csv')\n",
    "# Fix specific encoding errors in city names\n",
    "df['city_name'] = df['city_name'].replace('ÅŒita', 'Ōita')\n",
    "df['city_name'] = df['city_name'].replace('BrasÃlia', 'Brasília')\n",
    "df['city_name'] = df['city_name'].replace('CuiabÃ¡', 'Cuiabá')\n",
    "df['city_name'] = df['city_name'].replace('SÃ£o Paulo', 'São Paulo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3995f838-e3d5-42e3-97d5-33aef3242741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching coordinates for cities...\n",
      "Found Seoul: {'lat': 37.566, 'lon': 126.9784, 'timezone': 'Asia/Seoul'}\n",
      "Found Niigata: {'lat': 37.92259, 'lon': 139.04124, 'timezone': 'Asia/Tokyo'}\n",
      "Found Ulsan: {'lat': 35.53722, 'lon': 129.31667, 'timezone': 'Asia/Seoul'}\n",
      "Found Sapporo: {'lat': 43.06667, 'lon': 141.35, 'timezone': 'Asia/Tokyo'}\n",
      "Found Ibaraki: {'lat': 34.81641, 'lon': 135.56828, 'timezone': 'Asia/Tokyo'}\n",
      "Found Busan: {'lat': 35.10168, 'lon': 129.03004, 'timezone': 'Asia/Seoul'}\n",
      "Found Saitama: {'lat': 35.90807, 'lon': 139.65657, 'timezone': 'Asia/Tokyo'}\n",
      "Found Gwangju: {'lat': 35.15472, 'lon': 126.91556, 'timezone': 'Asia/Seoul'}\n",
      "Found Kobe: {'lat': 34.6913, 'lon': 135.183, 'timezone': 'Asia/Tokyo'}\n",
      "Found Suwon: {'lat': 37.29111, 'lon': 127.00889, 'timezone': 'Asia/Seoul'}\n",
      "Found Daegu: {'lat': 35.87028, 'lon': 128.59111, 'timezone': 'Asia/Seoul'}\n",
      "Found Jeonju: {'lat': 35.82194, 'lon': 127.14889, 'timezone': 'Asia/Seoul'}\n",
      "Found Seogwipo: {'lat': 33.25333, 'lon': 126.56181, 'timezone': 'Asia/Seoul'}\n",
      "Found Incheon: {'lat': 37.45646, 'lon': 126.70515, 'timezone': 'Asia/Seoul'}\n",
      "Found Yokohama: {'lat': 35.43333, 'lon': 139.65, 'timezone': 'Asia/Tokyo'}\n",
      "Found Miyagi (Manual): {'lat': 38.3291, 'lon': 140.9825, 'timezone': 'Asia/Tokyo'}\n",
      "Found Ōita: {'lat': 33.23333, 'lon': 131.6, 'timezone': 'Asia/Tokyo'}\n",
      "Found Shizuoka: {'lat': 34.98333, 'lon': 138.38333, 'timezone': 'Asia/Tokyo'}\n",
      "Found Daejeon: {'lat': 36.34913, 'lon': 127.38493, 'timezone': 'Asia/Seoul'}\n",
      "Found Osaka: {'lat': 34.69379, 'lon': 135.50107, 'timezone': 'Asia/Tokyo'}\n",
      "Found Munich: {'lat': 48.13743, 'lon': 11.57549, 'timezone': 'Europe/Berlin'}\n",
      "Found Gelsenkirchen: {'lat': 51.50508, 'lon': 7.09654, 'timezone': 'Europe/Berlin'}\n",
      "Found Frankfurt: {'lat': 52.34714, 'lon': 14.55062, 'timezone': 'Europe/Berlin'}\n",
      "Found Dortmund: {'lat': 51.51494, 'lon': 7.466, 'timezone': 'Europe/Berlin'}\n",
      "Found Hamburg: {'lat': 53.55073, 'lon': 9.99302, 'timezone': 'Europe/Berlin'}\n",
      "Found Leipzig: {'lat': 51.33962, 'lon': 12.37129, 'timezone': 'Europe/Berlin'}\n",
      "Found Nuremberg: {'lat': 49.45421, 'lon': 11.07752, 'timezone': 'Europe/Berlin'}\n",
      "Found Cologne: {'lat': 50.93333, 'lon': 6.95, 'timezone': 'Europe/Berlin'}\n",
      "Found Kaiserslautern: {'lat': 49.443, 'lon': 7.77161, 'timezone': 'Europe/Berlin'}\n",
      "Found Hanover: {'lat': 52.37052, 'lon': 9.73322, 'timezone': 'Europe/Berlin'}\n",
      "Found Stuttgart: {'lat': 48.78232, 'lon': 9.17702, 'timezone': 'Europe/Berlin'}\n",
      "Found Berlin: {'lat': 52.52437, 'lon': 13.41053, 'timezone': 'Europe/Berlin'}\n",
      "Found Cape Town: {'lat': -33.92584, 'lon': 18.42322, 'timezone': 'Africa/Johannesburg'}\n",
      "Found Johannesburg: {'lat': -26.20227, 'lon': 28.04363, 'timezone': 'Africa/Johannesburg'}\n",
      "Found Port Elizabeth: {'lat': -33.96109, 'lon': 25.61494, 'timezone': 'Africa/Johannesburg'}\n",
      "Found Rustenburg: {'lat': -25.66756, 'lon': 27.24208, 'timezone': 'Africa/Johannesburg'}\n",
      "Found Polokwane: {'lat': -23.90449, 'lon': 29.46885, 'timezone': 'Africa/Johannesburg'}\n",
      "Found Pretoria: {'lat': -25.74486, 'lon': 28.18783, 'timezone': 'Africa/Johannesburg'}\n",
      "Found Durban: {'lat': -29.8579, 'lon': 31.0292, 'timezone': 'Africa/Johannesburg'}\n",
      "Found Bloemfontein: {'lat': -29.12107, 'lon': 26.214, 'timezone': 'Africa/Johannesburg'}\n",
      "Found Nelspruit: {'lat': -25.47512, 'lon': 30.96935, 'timezone': 'Africa/Johannesburg'}\n",
      "Found São Paulo: {'lat': -23.5475, 'lon': -46.63611, 'timezone': 'America/Sao_Paulo'}\n",
      "Found Cuiabá: {'lat': -15.59611, 'lon': -56.09667, 'timezone': 'America/Cuiaba'}\n",
      "Found Salvador: {'lat': -12.97563, 'lon': -38.49096, 'timezone': 'America/Bahia'}\n",
      "Found Natal: {'lat': -5.795, 'lon': -35.20944, 'timezone': 'America/Fortaleza'}\n",
      "Found Belo Horizonte: {'lat': -19.92083, 'lon': -43.93778, 'timezone': 'America/Sao_Paulo'}\n",
      "Found Fortaleza: {'lat': -3.71722, 'lon': -38.54306, 'timezone': 'America/Fortaleza'}\n",
      "Found Manaus: {'lat': -3.10194, 'lon': -60.025, 'timezone': 'America/Manaus'}\n",
      "Found Recife: {'lat': -8.05389, 'lon': -34.88111, 'timezone': 'America/Recife'}\n",
      "Found Brasília: {'lat': -15.77972, 'lon': -47.92972, 'timezone': 'America/Sao_Paulo'}\n",
      "Found Porto Alegre: {'lat': -30.03283, 'lon': -51.23019, 'timezone': 'America/Sao_Paulo'}\n",
      "Found Rio de Janeiro: {'lat': -22.90642, 'lon': -43.18223, 'timezone': 'America/Sao_Paulo'}\n",
      "Found Curitiba: {'lat': -25.42778, 'lon': -49.27306, 'timezone': 'America/Sao_Paulo'}\n",
      "Found Moscow: {'lat': 55.75222, 'lon': 37.61556, 'timezone': 'Europe/Moscow'}\n",
      "Found Sochi: {'lat': 43.59699, 'lon': 39.72477, 'timezone': 'Europe/Moscow'}\n",
      "Found Yekaterinburg: {'lat': 56.8519, 'lon': 60.6122, 'timezone': 'Asia/Yekaterinburg'}\n",
      "Found Saint Petersburg: {'lat': 59.93863, 'lon': 30.31413, 'timezone': 'Europe/Moscow'}\n",
      "Found Kazan: {'lat': 55.78874, 'lon': 49.12214, 'timezone': 'Europe/Moscow'}\n",
      "Found Saransk: {'lat': 54.1838, 'lon': 45.1749, 'timezone': 'Europe/Moscow'}\n",
      "Found Kaliningrad: {'lat': 54.70649, 'lon': 20.51095, 'timezone': 'Europe/Kaliningrad'}\n",
      "Found Samara: {'lat': 53.20007, 'lon': 50.15, 'timezone': 'Europe/Samara'}\n",
      "Found Rostov-on-Don: {'lat': 47.23135, 'lon': 39.72328, 'timezone': 'Europe/Moscow'}\n",
      "Found Nizhny Novgorod: {'lat': 56.32867, 'lon': 44.00205, 'timezone': 'Europe/Moscow'}\n",
      "Found Volgograd: {'lat': 48.71939, 'lon': 44.50183, 'timezone': 'Europe/Volgograd'}\n",
      "Found Al Khor: {'lat': 25.68389, 'lon': 51.50583, 'timezone': 'Asia/Qatar'}\n",
      "Found Al Rayyan: {'lat': 25.29194, 'lon': 51.42444, 'timezone': 'Asia/Qatar'}\n",
      "Found Doha: {'lat': 25.28545, 'lon': 51.53096, 'timezone': 'Asia/Qatar'}\n",
      "Found Lusail (Manual): {'lat': 25.418, 'lon': 51.4902, 'timezone': 'Asia/Qatar'}\n",
      "Found Al Wakrah: {'lat': 25.17151, 'lon': 51.60337, 'timezone': 'Asia/Qatar'}\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# 2. Automated Geocoding\n",
    "# ------------------------------------------------------\n",
    "# Identify all the cities and fetch their coordinates and time zones\n",
    "unique_locations = df[['city_name', 'country_name']].drop_duplicates()\n",
    "city_coords = {}\n",
    "\n",
    "# Force the correct data for cities the API misses or gets wrong\n",
    "manual_overrides = {\n",
    "    'Lusail': {'lat': 25.4180, 'lon': 51.4902, 'timezone': 'Asia/Qatar'},\n",
    "    'Miyagi': {'lat': 38.3291, 'lon': 140.9825, 'timezone': 'Asia/Tokyo'}, \n",
    "}\n",
    "\n",
    "print(\"Fetching coordinates for cities...\")\n",
    "\n",
    "# Setup for geocoding\n",
    "geocoding_url = \"https://geocoding-api.open-meteo.com/v1/search\"\n",
    "\n",
    "for index, row in unique_locations.iterrows():\n",
    "    city = row['city_name']\n",
    "    \n",
    "    # 1. Check if manual override first\n",
    "    if city in manual_overrides:\n",
    "        city_coords[city] = manual_overrides[city]\n",
    "        print(f\"Found {city} (Manual): {city_coords[city]}\")\n",
    "        continue\n",
    "    \n",
    "    # 2. If not, ask API\n",
    "    if city in city_coords:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        params = {\"name\": city, \"count\": 5, \"language\": \"en\", \"format\": \"json\"}\n",
    "        response = requests.get(geocoding_url, params=params)\n",
    "        results = response.json().get(\"results\", [])\n",
    "        \n",
    "        if results:\n",
    "            best_match = results[0]\n",
    "            city_coords[city] = {\n",
    "                'lat': best_match['latitude'],\n",
    "                'lon': best_match['longitude'],\n",
    "                'timezone': best_match['timezone']\n",
    "            }\n",
    "            # Updated print statement to show Lat/Lon\n",
    "            print(f\"Found {city}: {city_coords[city]}\")\n",
    "        else:\n",
    "            print(f\"Could not find coordinates for {city}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error Geocoding {city}: {e}\")\n",
    "    \n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9d90769-9b4e-4e1d-aba3-b2a8319ea8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# 3. Setup Open-Meteo API\n",
    "# ------------------------------------------------------\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2306e03a-5e6d-429c-885b-93c00f4cf201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# 4. Lists to store new data\n",
    "# ------------------------------------------------------\n",
    "weather_data = {\n",
    "    'temp0': [], 'temp1': [], 'temp2': [],\n",
    "    'atemp0': [], 'atemp1': [], 'atemp2': [],\n",
    "    'humid0': [], 'humid1': [], 'humid2': [],\n",
    "    'wind0': [], 'wind1': [], 'wind2': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e96bdd5-d036-4f2b-8599-8bde1389f424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 384 matches...\n",
      "Processing row 0/384: Seoul on 2002-05-31\n",
      "Processing row 10/384: Ulsan on 2002-06-03\n",
      "Processing row 20/384: Kobe on 2002-06-07\n",
      "Processing row 30/384: Ōita on 2002-06-10\n",
      "Processing row 40/384: Suwon on 2002-06-13\n",
      "Processing row 50/384: Ōita on 2002-06-16\n",
      "Processing row 60/384: Seoul on 2002-06-25\n",
      "Processing row 70/384: Nuremberg on 2006-06-11\n",
      "Processing row 80/384: Leipzig on 2006-06-14\n",
      "Processing row 90/384: Munich on 2006-06-18\n",
      "Processing row 100/384: Frankfurt on 2006-06-21\n",
      "Processing row 110/384: Kaiserslautern on 2006-06-23\n",
      "Processing row 120/384: Hamburg on 2006-06-30\n",
      "Processing row 130/384: Port Elizabeth on 2010-06-12\n",
      "Processing row 140/384: Rustenburg on 2010-06-15\n",
      "Processing row 150/384: Port Elizabeth on 2010-06-18\n",
      "Processing row 160/384: Bloemfontein on 2010-06-22\n",
      "Processing row 170/384: Polokwane on 2010-06-24\n",
      "Processing row 180/384: Durban on 2010-06-28\n",
      "Processing row 190/384: Port Elizabeth on 2010-07-10\n",
      "Processing row 200/384: Brasília on 2014-06-15\n",
      "Processing row 210/384: Porto Alegre on 2014-06-18\n",
      "Processing row 220/384: Cuiabá on 2014-06-21\n",
      "Processing row 230/384: Cuiabá on 2014-06-24\n",
      "Processing row 240/384: Belo Horizonte on 2014-06-28\n",
      "Processing row 250/384: Brasília on 2014-07-05\n",
      "Processing row 260/384: Kazan on 2018-06-16\n",
      "Processing row 270/384: Saint Petersburg on 2018-06-19\n",
      "Processing row 280/384: Volgograd on 2018-06-22\n",
      "Processing row 290/384: Kaliningrad on 2018-06-25\n",
      "Processing row 300/384: Kaliningrad on 2018-06-28\n",
      "Processing row 310/384: Saint Petersburg on 2018-07-03\n",
      "Processing row 320/384: Al Khor on 2022-11-20\n",
      "Processing row 330/384: Doha on 2022-11-23\n",
      "Processing row 340/384: Lusail on 2022-11-26\n",
      "Processing row 350/384: Doha on 2022-11-28\n",
      "Processing row 360/384: Al Rayyan on 2022-12-01\n",
      "Processing row 370/384: Doha on 2022-12-04\n",
      "Processing row 380/384: Lusail on 2022-12-13\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# 5. Iterate through matches and fetch data\n",
    "# ------------------------------------------------------\n",
    "print(f\"Processing {len(df)} matches...\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    city = row['city_name']\n",
    "    match_date = row['match_date'] # Format YYYY-MM-DD\n",
    "    match_time = row['match_time'] # Format HH:MM\n",
    "    \n",
    "    # Progress indicator\n",
    "    if index % 10 == 0:\n",
    "        print(f\"Processing row {index}/{len(df)}: {city} on {match_date}\")\n",
    "\n",
    "    if city not in city_coords:\n",
    "        print(f\"Warning: Coordinates for {city} not found.\")\n",
    "        for key in weather_data: weather_data[key].append(None)\n",
    "        continue\n",
    "        \n",
    "    loc = city_coords[city]\n",
    "    \n",
    "    # Prepare API params\n",
    "    # Request data for the match day and the next day to handle matches near midnight\n",
    "    date_obj = datetime.strptime(match_date, '%Y-%m-%d')\n",
    "    end_date_obj = date_obj + timedelta(days=1)\n",
    "    \n",
    "    params = {\n",
    "        \"latitude\": loc['lat'],\n",
    "        \"longitude\": loc['lon'],\n",
    "        \"start_date\": match_date,\n",
    "        \"end_date\": end_date_obj.strftime('%Y-%m-%d'),\n",
    "        \"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"apparent_temperature\", \"wind_speed_10m\"],\n",
    "        \"timezone\": loc['timezone']\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        responses = openmeteo.weather_api(url, params=params)\n",
    "        response = responses[0]\n",
    "        \n",
    "        # Get hourly data\n",
    "        hourly = response.Hourly()\n",
    "        \n",
    "        # Extract variables as numpy arrays\n",
    "        # Note: Order matches the \"hourly\" list in params\n",
    "        temp_arr = hourly.Variables(0).ValuesAsNumpy()\n",
    "        humid_arr = hourly.Variables(1).ValuesAsNumpy()\n",
    "        atemp_arr = hourly.Variables(2).ValuesAsNumpy()\n",
    "        wind_arr = hourly.Variables(3).ValuesAsNumpy()\n",
    "        \n",
    "        # Calculate Index\n",
    "        # API returns data starting at 00:00 local time of start_date.\n",
    "        # Thus, index 0 = 00:00, index 10 = 10:00.\n",
    "        match_hour = int(match_time.split(':')[0])\n",
    "        \n",
    "        # Want hour, hour+1, hour+2\n",
    "        indices = [match_hour, match_hour + 1, match_hour + 2]\n",
    "        \n",
    "        # Append data\n",
    "        weather_data['temp0'].append(temp_arr[indices[0]])\n",
    "        weather_data['temp1'].append(temp_arr[indices[1]])\n",
    "        weather_data['temp2'].append(temp_arr[indices[2]])\n",
    "        \n",
    "        weather_data['humid0'].append(humid_arr[indices[0]])\n",
    "        weather_data['humid1'].append(humid_arr[indices[1]])\n",
    "        weather_data['humid2'].append(humid_arr[indices[2]])\n",
    "        \n",
    "        weather_data['atemp0'].append(atemp_arr[indices[0]])\n",
    "        weather_data['atemp1'].append(atemp_arr[indices[1]])\n",
    "        weather_data['atemp2'].append(atemp_arr[indices[2]])\n",
    "        \n",
    "        weather_data['wind0'].append(wind_arr[indices[0]])\n",
    "        weather_data['wind1'].append(wind_arr[indices[1]])\n",
    "        weather_data['wind2'].append(wind_arr[indices[2]])\n",
    "        \n",
    "        time.sleep(0.2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {city} on {match_date}: {e}\")\n",
    "        for key in weather_data: weather_data[key].append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cb3a8df-7f97-4412-a5a3-317c19d51def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Updated file saved as ../data-processed/matches_clean_weather.csv\n",
      "  city_name  match_date match_time      temp0     humid0\n",
      "0     Seoul  2002-05-31      20:30  17.914000  90.946243\n",
      "1   Niigata  2002-06-01      15:30  22.896000  65.320168\n",
      "2     Ulsan  2002-06-01      18:00  22.579498  76.212860\n",
      "3   Sapporo  2002-06-01      20:30  14.346000  87.780296\n",
      "4   Ibaraki  2002-06-02      14:30  26.892500  41.430252\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# 6. Add columns to df and save\n",
    "# ------------------------------------------------------\n",
    "for key, values in weather_data.items():\n",
    "    df[key] = values\n",
    "\n",
    "output_filename = '../data-processed/matches_clean_weather.csv'\n",
    "df.to_csv(output_filename, index=False)\n",
    "print(f\"Done! Updated file saved as {output_filename}\")\n",
    "print(df[['city_name', 'match_date', 'match_time', 'temp0', 'humid0']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
